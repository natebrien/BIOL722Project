## Running gargammel

- tried to activate conda env I used earlier by running:
`$ conda activate /home/sam/envs/gargammel`

but it didn't work, gave the error: not a conda environment

Just had the wrong path: should be /home/sam/miniconda3/envs/gargammel
- activated gargammel env
- cd'd into my files and the gargammel folder with the data I need

Missing: frequency distribution data...how to get this:
- [x] check github documentation for a preset file (similar to damage)
- [x] check literature?
- [ ] run a program (mapDamage????) to get representative info

Hmm... in the interest of time would it possibly be better to just pass gargammel a specific length? It is possible to just specify
`-l 45`
Or whatever length necessary. How would that change things downstream?
- I wouldn't get proper FLDs (since everything is the same length)
	- we would normally use FLDs to look at whether sequences are genuine or not, so may this isn't the biggest deal in this application
Decision: timing is an issue, this project needs to be finished by end of April and I'm still on the first step - let's go with the simpler option of a defined length

Which length to choose?
Ancient samples typically peak around 30s - defined length 35 bp

I did specify max-size, I probably don't need to after this - take this out of the code. 

Run #1: First real run!!!
` $ gargammel -o results/ -l 35 -n 1000  -damage 0.024,0.36,0.0097,0.68 data`

Results: forgot to specify prefix for output files...run again with prefix and run `time` as well to get how long it took (for info purposes)

Run #2: 
`$ time gargammel -o results/sim_data -l 35 -n 1000 -damage 0.024,0.36,0.0097,0.68 data`

Results from `time`: 
real    0m27.979s
user    0m2.483s
sys     0m3.199s

## Quality control

Yay!! All done this step. Now onto quality control checks for this data
We expect to see: 
- all fragment lengths the same
- some deamination damage

Need to logout from info2020, it does not have fastqc installed
(maybe I can install using conda??)

`conda activate quality-control-env`
`conda install -c bioconda fastqc`

Installed!
To run fastqc on paired-end read data from gargammel: 

Run #1: 
`$ fastqc results/sim_data_s1.fq.gz results/sim_data_s2.fq.gz --outdir quality_control/`

Take a look at these files...
download .html files to local computer and then inspect

`$ scp sim_data_s1_fastqc.html sim_data_s2_fastqc.html natas@DESKTOP-70OCG84: C:\Users\natas\Downloads

This is taking a while....html files are not that large so what is happening to cause scp to hang up like this
Got error: connection timed out

restarted Moba and used the SSH file browser to download html files and open using Edge

Files look OK but fastqc doesn't show deamination damage...how can I create plots...map to human then run mapDamage?

mapDamage located on info115, needs SAM or BAM file for input
also needs a fasta file for reference

Plan:
1. Use bwa-aln to align reads to human genome
2. run mapDamage on SAM file output to generate a deamination plot

Questions: 
- should I process and quality filter first using fastp? YES, otherwise reads will still have simulated adapters 
- to merge or not to merge, that is the question...should I merge reads using fastp or just leave them unmerged?
	- follow-up, do I need merged or unmerged reads to feed into bwa?

Okay, bwa looks like it will take both types of files. However, they do need to be indexed using 
`bwa index [file]` 
before running the alignment

Which to use? bwa has three algorithms
- aln - 
- mem - stands for maximal exact matches, 
- sw - 

WAIT! Still need to run fastp first, let's think about what parameters make sense

Ran
`conda activate quality-control-env`
`conda install -c bioconda fastp`


